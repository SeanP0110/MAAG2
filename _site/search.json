{
  "articles": [
    {
      "path": "about.html",
      "title": "About",
      "description": "This website contains a collection of the projects and visualisation I have completed during my Singapore Management University Master of IT in Business (Analytics) journey. Enjoy looking around and diving into my personal viz display.",
      "author": [],
      "contents": "\r\n\r\n\r\n\r\n",
      "last_modified": "2022-01-28T23:01:52+08:00"
    },
    {
      "path": "index.html",
      "title": "My Analytics Art Gallery",
      "description": "This is my project site for my visual analytics course and beyond!\n",
      "author": [],
      "contents": "\r\n\r\n\r\n\r\n",
      "last_modified": "2022-01-28T23:01:30+08:00"
    },
    {
      "path": "THEx1.html",
      "title": "Take Home Exercise 1",
      "description": "Here is the take home exercise 1 solution as interpreted by me. The first part of this article looks at a Pareto Diagram describing the returns by item sub-category in a supermarket. The second part of the post portrays Singapore's population pyramid as divided by sex.\n",
      "author": [
        {
          "name": "Sean Samuel Prajs",
          "url": "https://github.com/SeanP0110"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\r\nNecessary Libraries\r\nThe libraries used for this exercise are going to be tidyverse, readxl, and knitr. They are installed and uploaded using the following chunk of code:\r\n\r\n\r\npackages = c('tidyverse', 'readxl', 'knitr')\r\n\r\nfor(p in packages){\r\n  if(!require(p, character.only = T)){\r\n    install.packages(p)\r\n  }\r\n  library(p, character.only = T)\r\n}\r\n\r\n\r\n\r\nPareto Diagram\r\nThe Pareto Chart consists of two pieces. A bar chart showing the absolute frequency of returns by category and a line chart showing the proportional cumulative frequency of returns.\r\nData Source\r\nThe file used for this exercise has been provided by the professor and is called: Superstore-2021.xls\r\nData Upload and Preparation\r\nThe file has 3 sheets: Orders, Returns, and People. For this exercise we only need Orders and Returns. We upload them to R using the following code:\r\n\r\n\r\norders <- read_xls(\"data/Superstore-2021.xls\", sheet = \"Orders\")\r\nreturns <- read_xls(\"data/Superstore-2021.xls\", sheet = \"Returns\")\r\n\r\n\r\n\r\nIn order to process the data accurately, we need to join the two sheets. But, what is the common variable we can join them on? Time to look at the table summary for both.\r\n\r\n\r\nstr(orders)\r\n\r\n\r\ntibble [9,994 x 21] (S3: tbl_df/tbl/data.frame)\r\n $ Row ID        : num [1:9994] 1 2 3 4 5 6 7 8 9 10 ...\r\n $ Order ID      : chr [1:9994] \"CA-2020-152156\" \"CA-2020-152156\" \"CA-2020-138688\" \"US-2019-108966\" ...\r\n $ Order Date    : POSIXct[1:9994], format: \"2020-11-08\" ...\r\n $ Ship Date     : POSIXct[1:9994], format: \"2020-11-11\" ...\r\n $ Ship Mode     : chr [1:9994] \"Second Class\" \"Second Class\" \"Second Class\" \"Standard Class\" ...\r\n $ Customer ID   : chr [1:9994] \"CG-12520\" \"CG-12520\" \"DV-13045\" \"SO-20335\" ...\r\n $ Customer Name : chr [1:9994] \"Claire Gute\" \"Claire Gute\" \"Darrin Van Huff\" \"Sean O'Donnell\" ...\r\n $ Segment       : chr [1:9994] \"Consumer\" \"Consumer\" \"Corporate\" \"Consumer\" ...\r\n $ Country/Region: chr [1:9994] \"United States\" \"United States\" \"United States\" \"United States\" ...\r\n $ City          : chr [1:9994] \"Henderson\" \"Henderson\" \"Los Angeles\" \"Fort Lauderdale\" ...\r\n $ State         : chr [1:9994] \"Kentucky\" \"Kentucky\" \"California\" \"Florida\" ...\r\n $ Postal Code   : num [1:9994] 42420 42420 90036 33311 33311 ...\r\n $ Region        : chr [1:9994] \"South\" \"South\" \"West\" \"South\" ...\r\n $ Product ID    : chr [1:9994] \"FUR-BO-10001798\" \"FUR-CH-10000454\" \"OFF-LA-10000240\" \"FUR-TA-10000577\" ...\r\n $ Category      : chr [1:9994] \"Furniture\" \"Furniture\" \"Office Supplies\" \"Furniture\" ...\r\n $ Sub-Category  : chr [1:9994] \"Bookcases\" \"Chairs\" \"Labels\" \"Tables\" ...\r\n $ Product Name  : chr [1:9994] \"Bush Somerset Collection Bookcase\" \"Hon Deluxe Fabric Upholstered Stacking Chairs, Rounded Back\" \"Self-Adhesive Address Labels for Typewriters by Universal\" \"Bretford CR4500 Series Slim Rectangular Table\" ...\r\n $ Sales         : num [1:9994] 262 731.9 14.6 957.6 22.4 ...\r\n $ Quantity      : num [1:9994] 2 3 2 5 2 7 4 6 3 5 ...\r\n $ Discount      : num [1:9994] 0 0 0 0.45 0.2 0 0 0.2 0.2 0 ...\r\n $ Profit        : num [1:9994] 41.91 219.58 6.87 -383.03 2.52 ...\r\n\r\nstr(returns)\r\n\r\n\r\ntibble [800 x 2] (S3: tbl_df/tbl/data.frame)\r\n $ Returned: chr [1:800] \"Yes\" \"Yes\" \"Yes\" \"Yes\" ...\r\n $ Order ID: chr [1:800] \"CA-2018-100762\" \"CA-2018-100762\" \"CA-2018-100762\" \"CA-2018-100762\" ...\r\n\r\nOrder ID is the common denominator here. Given that we are looking at returns, we should ideally left join returns and orders. This can be done with the following command.\r\n\r\n\r\njoin <- left_join(returns, orders, by = c(\"Order ID\" = \"Order ID\"))\r\nstr(join)\r\n\r\n\r\ntibble [3,226 x 22] (S3: tbl_df/tbl/data.frame)\r\n $ Returned      : chr [1:3226] \"Yes\" \"Yes\" \"Yes\" \"Yes\" ...\r\n $ Order ID      : chr [1:3226] \"CA-2018-100762\" \"CA-2018-100762\" \"CA-2018-100762\" \"CA-2018-100762\" ...\r\n $ Row ID        : num [1:3226] 6315 6316 6317 6318 6315 ...\r\n $ Order Date    : POSIXct[1:3226], format: \"2018-11-24\" ...\r\n $ Ship Date     : POSIXct[1:3226], format: \"2018-11-29\" ...\r\n $ Ship Mode     : chr [1:3226] \"Standard Class\" \"Standard Class\" \"Standard Class\" \"Standard Class\" ...\r\n $ Customer ID   : chr [1:3226] \"NG-18355\" \"NG-18355\" \"NG-18355\" \"NG-18355\" ...\r\n $ Customer Name : chr [1:3226] \"Nat Gilpin\" \"Nat Gilpin\" \"Nat Gilpin\" \"Nat Gilpin\" ...\r\n $ Segment       : chr [1:3226] \"Corporate\" \"Corporate\" \"Corporate\" \"Corporate\" ...\r\n $ Country/Region: chr [1:3226] \"United States\" \"United States\" \"United States\" \"United States\" ...\r\n $ City          : chr [1:3226] \"Jackson\" \"Jackson\" \"Jackson\" \"Jackson\" ...\r\n $ State         : chr [1:3226] \"Michigan\" \"Michigan\" \"Michigan\" \"Michigan\" ...\r\n $ Postal Code   : num [1:3226] 49201 49201 49201 49201 49201 ...\r\n $ Region        : chr [1:3226] \"Central\" \"Central\" \"Central\" \"Central\" ...\r\n $ Product ID    : chr [1:3226] \"OFF-AR-10000380\" \"OFF-LA-10003930\" \"OFF-PA-10001815\" \"OFF-PA-10004082\" ...\r\n $ Category      : chr [1:3226] \"Office Supplies\" \"Office Supplies\" \"Office Supplies\" \"Office Supplies\" ...\r\n $ Sub-Category  : chr [1:3226] \"Art\" \"Labels\" \"Paper\" \"Paper\" ...\r\n $ Product Name  : chr [1:3226] \"Hunt PowerHouse Electric Pencil Sharpener, Blue\" \"Dot Matrix Printer Tape Reel Labels, White, 5000/Box\" \"Xerox 1885\" \"Adams Telephone Message Book w/Frequently-Called Numbers Space, 400 Messages per Book\" ...\r\n $ Sales         : num [1:3226] 152 197 144 16 152 ...\r\n $ Quantity      : num [1:3226] 4 2 3 2 4 2 3 2 4 2 ...\r\n $ Discount      : num [1:3226] 0 0 0 0 0 0 0 0 0 0 ...\r\n $ Profit        : num [1:3226] 45.58 96.34 69.18 7.98 45.58 ...\r\n\r\nNow that we have both files merged together, it is time to extract the necessary data.\r\n\r\n\r\nfreq_returned <- join %>% \r\n  count(`Sub-Category`) %>%\r\n  rename(Returns = n)\r\n# Here the returns per sub-category are counted and then saved within a new tibble (data frame).\r\n\r\nfreq_sort <- freq_returned %>% arrange(desc(Returns))\r\n#For the purposes of preparing the graph, we sort the sub-categories by number of returns in descending order.\r\n\r\nfreq_cum <- freq_sort %>% mutate(CumReturns = cumsum(Returns))\r\n#Next we use the cumsum function to add a cumulative frequency column.\r\n\r\nfreq_cum_prop <- freq_cum %>% mutate(\r\n  PropCumReturns = CumReturns/sum(Returns))\r\n#Lastly, we add a column for proportional cumulative frequency. This is each cumulative frequency divided by the total number of returns.\r\n\r\n\r\n\r\nBar Chart\r\nNow that we are done with the data prep, time for the first viz.\r\n\r\n\r\nbar <- freq_cum_prop %>% ggplot(aes(reorder(`Sub-Category`, -Returns), Returns)) + \r\n  geom_col(color = \"blue\", fill = \"blue\") +\r\n  labs(title = \"No. of Returns ber Sub-Category\", x = \"Sub-Catgory\") +\r\n  scale_y_continuous(limits= c(0,sum(freq_cum_prop$Returns),100)) +\r\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\r\n\r\n\r\n\r\nThe code for the bar graph is shown above. We use the geon_col method to create a bar chart. Our x variable are the sub-categories ordered from highest to lowest number of returns. The heigh of the bar is determind by Returns. Moreover, the colour is set to blue for both the outline and the fill of the bar. I also added a more coherent x axis title and altered the scale to be adequate for fusion with the line plot. Given the high number of elements within the variable “Sub-Category,” I decided to tilt the labels by 90 degrees to avoid overlap. The result is:\r\n\r\n\r\n\r\nLine Plot\r\nThe second element of the Pareto Diagram is the line plot showing the proportional cumulative frequency of the data. This means, that each point represents the sum of the fractions of the total number of returns of each category up to that point (inclusive of the category the point is at).\r\nNow that we are done with the data prep, time for the first viz.\r\n\r\n\r\nline <- freq_cum_prop %>% ggplot(aes(\r\n  reorder(`Sub-Category`, PropCumReturns), PropCumReturns)) +\r\n  geom_point(shape = 19, size = 1.5) + \r\n  geom_path(aes(reorder(`Sub-Category`, PropCumReturns), group = 1)) +\r\n  scale_y_continuous(labels = scales::percent_format()) +\r\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +\r\n  labs(title = \"Cumulative Frequency of Returns per Sub-Category\", x = \"Sub-Category\")\r\n\r\n\r\n\r\nFor the line plot, the relative cumulative frequency is used on the y-axis. It is plotted in the following way:\r\nA scatter plot of the relative cumulative frequencies. This is achieved through geom_point.\r\nWe have to draw a line that follows the points. For this, geom_path has been used.\r\nscale_y_continuous is used to convert the axis into percentage format.\r\nAs in the bar chart, the labels of the x-axis are rotated by 90 degrees and the x-axis title and graph title are added.\r\nThe final output is this:\r\n\r\n\r\n\r\nPutting the Graphs Together\r\nNow that we have the separate elements of the Pareto Chart, we just need to put them together. This can simply happen by adding the two graphs together. However, we need to also add a second y-axis. A handy tool for transforming the y axis is going to be the constant of the total sum of returns, calculated below.\r\n\r\n\r\ntot_returns = sum(freq_cum_prop$Returns)\r\ntot_returns\r\n\r\n\r\n[1] 3226\r\n\r\nThe code for the Pareto Chart:\r\n\r\n\r\npareto <-\r\n  freq_cum_prop %>% ggplot(aes(reorder(`Sub-Category`, -Returns), Returns)) + \r\n  geom_col(color = \"blue\", fill = \"blue\") +\r\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +\r\n  geom_point(aes(reorder(`Sub-Category`, PropCumReturns), PropCumReturns*tot_returns), \r\n             shape = 19, size = 1.5) + \r\n  geom_path(aes(reorder(`Sub-Category`, PropCumReturns), PropCumReturns*tot_returns, group = 1)) +\r\n  #in geom_point and geom_path we transform the y values with the reverse transformation with\r\n  #what we do to the y-axis\r\n  scale_y_continuous(\"Absolute Frequency of Returns\", sec.axis = \r\n                       sec_axis(~.*1/tot_returns, name = \"Relative Cumulative Frequency of Returns (%)\",\r\n                                labels = scales::percent_format()),\r\n                     #the above line of code transforms the first y-axis to create the second\r\n                     limits= c(0,sum(freq_cum_prop$Returns),100)) +\r\n  labs(title = \"Pareto Chart of Return Frequencies by Sub-Category\", x = \"Sub-Catgory\")\r\n\r\n\r\n\r\nsec_axis is used to transform the left y-axis and form a second y-axis on the right. We transform the absolute frequency to the relative cumulative frequency by dividing the values by the total number of returns as saved in tot_returns. As mentioned in the code, due to this, we also have to change the y values in the geom_point and geom_path arguments. This is to map the line plot onto the second y axis. In order to achieve this, we just use the reverse transformation of the y-axis. This means we multiply the y values by tot_returns.\r\nFinally, we get the following output:\r\n\r\n\r\n\r\nWhat a beautiful graph!\r\nAge Sex Graph Singapore (Population Pyramid Singapore)\r\nIn the second part of this take home exercise, I will show a visualisation of Singapore’s population pyramid.\r\nData Source\r\nThe data is taken from https://www.singstat.gov.sg/. It is the population data of Singapore from 2021.\r\nData Upload and Preparation\r\nDistill is a publication format for scientific and technical writing, native to the web.\r\nAttempt Summary\r\nSadly, I have not managed to complete this diagram in time. I had issues such as an identical count for each age group within the dataset that I could not resolve. Here is my attempted code:\r\n\r\n\r\n\r\nDistill\r\nLearn more about using Distill for R Markdown at https://rstudio.github.io/distill.\r\n\r\n\r\n\r\n",
      "last_modified": "2022-01-28T23:54:08+08:00"
    }
  ],
  "collections": []
}
